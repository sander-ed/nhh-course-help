---
title: "BAN400 HOME EXAM, FALL 2022, Candidate no 16"
output: html_document
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = F)
```

```{r, include=FALSE}
# First of all we need to include the correct file structure in order for the script to run.
# 1. The raw data must be placed in the working directory.
# 2. The HTML-output of this .Rmd file will be placed in the working directory
# 3. All temporary data generated by this script will be placed in a directory called "data",
#    which is generated below

dir.create("data")

# The .Rmd file is also quite slow to render, although this is mostly a result of the assert_that tests
# I have tried to utilize parallelization where it would give a significant performance boost.


```

# Introduction

This project will use insight from the course BAN400 in order to analyze the data provided from S2020. According to the exam information I will not make any significant changes to this template document, such as removing messages from some of the functions which do not provide any significant information. I will also not "hide" any code from the finished HTML-file as I would in a normal report. Comments within the code is used to clarify assumptions and improve readability.

The libraries which has been covered in the course and is used in this project are presented below. If they are not already installed this should be done before compiling the file.

```{r, message=FALSE}
  library(tidyverse)
  library(magrittr)
  library(readxl)
  library(assertthat)
  library(doParallel)
  library(rnaturalearth)
  library(rnaturalearthdata)
  library(rgeos)
  library(sf)
```

Due to the nature of some of the tasks, there are also some additional packages that are used in certain scenarios which has not been covered in this course. These must be installed to successfully compile the `.Rmd`-file.

```{r, message=FALSE}
  library(data.table)
  library(gganimate)
  library(transformr)
  library(gifski)
```

# Stefanski pandemic data

## Problem 1
The graph generated from the provided code is shown below.
```{r, eval=T, error=TRUE, message=TRUE, echo = FALSE}
# I have not made any alterations to it, so I have chosen to only include the results in the finished html-file.

# Load data, select relevant variables:
df <-
  read_excel("Stefanski-pandemic-data.xlsx") %>%
  select(-tree_ring, -pandemic_pc, -gdp)

# Define function for estimating regression for a given
# point of the impulse response function, and return a
# data frame of coefficients with summary statistics:
runreg <-
  function(h, df) {
    df %>%
      select(country, year, ln_gdp, pandemic_01, war) %>%
      mutate(country = factor(country)) %>%
      group_by(country) %>%
      mutate(
        lead_ln_gdp = lead(ln_gdp, h, order_by = year),
        lag_1_pandemic_01 = lag(pandemic_01, 1, order_by = year),
        lag_1_war = lag(war, 1, order_by = year),
        lag_ln_gdp = lag(ln_gdp, 1, order_by = year),
        vienna = case_when(year >= 1815 ~ 1, TRUE ~ 0),
        ww2 = case_when(year >= 1945 ~ 1, TRUE ~ 0),
        oil = case_when(year >= 1973 ~ 1, TRUE ~ 0),
        vienna_t = vienna * year,
        ww2_t = ww2 * year,
        oil_t = oil * year
      ) %>%
      ungroup() %>%
      lm(
        lead_ln_gdp ~
          country + lag_ln_gdp + pandemic_01 +
          lag_1_pandemic_01 + year + war +
          lag_1_war + vienna + oil + year +
          ww2 + vienna_t + oil_t + ww2_t,
        data = .
      ) %>%
      summary() %>%
      .$coefficients %>%
      as.data.frame() %>%
      rownames_to_column() %>%
      as_tibble() %>%
      mutate(h = h)
  }
# Iterate over h=0,...,40, and estimate the different
# IRF(h) coefficients. Thereafter, plot the results
lapply(0:40, FUN = runreg, df = df) %>%
  bind_rows() %>%
  filter(rowname == "pandemic_01") %>%
  ggplot(aes(x = h)) +
  geom_line(aes(y = Estimate * 100)) +
  geom_ribbon(aes(
    ymin = (Estimate - 1.96 * `Std. Error`) * 100,
    ymax = (Estimate + 1.96 * `Std. Error`) * 100
  ), alpha = .1) +
  geom_hline(yintercept = 0) +
  xlab("Fcast horizon") +
  ylab("Impulse response, percent") +
  ggtitle("Estimated impulse response of pandemics on GDP pr capita") +
  theme_classic()

```

Comparing this generated figure with the one presented in Figure 9 in S2020, it would not be unreasonable to assess that this simpler model captures many of the same trends as the more advanced model. As to why the results are similar, we can use some statistical knowledge from previous courses in order to explain this.

1.  The simpler model is able to explain the main *drivers* of the data. If there are some clear trends in the data set, then a simpler model would also be able to capture this effect with reasonable efficiency.
2.  The use of panel data might be a good abstraction of the exogenous shock variable in the model used in S2020.

There are however some differences which are worth noting. In the simplified model, one can observe that the standard deviation increases over time, whilst in Figure 9 it seems relatively stable. This might be a symptom of simplification of the model, although this assertion is by no means certain.

## Problem 2
I have approached this problem in a very similar way as to what is described in the task. I have created a function which simulates a country's ln_gdp over time based on a set of normally distributed variables which can be fine-tuned with a set of parameters given as inputs to the function. Next, I created a function which looped over this simulation `N`-times which in total creates a data frame with `N` amount of countries simulated.

I have made some assumptions in this task, most of which are presented as comments in the code. An example of this is for the alpha-value, which has a comment `# Assume that alpha is a constant value for each country i`. I will treat further assumptions in the same manner as this goring forward.

```{r, eval=T, error=TRUE, message=TRUE}
# *** One Country ***

# This function simulates a given countries reaction to a pandemic
sim_one_country <- function(country, T, p_pand, p_war, sigma, coeff_lag_ln_gdp, impulse_response, sigma_initial_value, sigma_alpha){
  # Fist we create a tibble for us to store the following results of the simulations
  pandemic.df <- tibble(
    country = country,
    year = seq(1:T),
    ln_gdp = NA,
    alpha = rnorm(1, sd=sigma_alpha),                 # Assume that alpha is a constant value for each country i
    sigma_error =rnorm(mean = 0, sd = sigma, n = T),  # Assume that the error is different for each T
    pandemic_01 = rbinom(n = T, size = 1, prob = p_pand),
    war = rbinom(n = T, size = 1, prob = p_war)
  )
  
  # Then we store an initial value for ln_gdp in the first row
  pandemic.df[1,"ln_gdp"] <- pandemic.df$alpha[1] + rnorm(1, sd=sigma_initial_value)
  
  # To make sure the model does not fail with a impulse_response larger than T we add
  # some `ghost-rows` which is onyl used to place excess data, and is later removed.
  pandemic.df[(T+1):(T+length(impulse_response)),] <- 0
  
  # We create a loop which determines the various IRF values from t+h
  # where h is amount of time passed since a given pandemic
  
  if(T>1){                       # The loop only runs if T>1 (ln_gdp[1] is already established)
    for(t in 2:T){               # for all values between 2 and T
      irf_sum <- 0               # Initialize sum value for IRF
      for(h in 0:(length(impulse_response)-1)) {                   # length(impulse_response) = M
        if(t - h >= 1){
          irf_temp <- impulse_response[h+1]*pandemic.df$pandemic_01[t-h]
          irf_sum <- irf_sum + irf_temp
        }
      }
      pandemic.df$ln_gdp[t] <-                                     # Then we add all the figures
        pandemic.df$alpha[t] +                                     # together according to the 
        (coeff_lag_ln_gdp * pandemic.df$ln_gdp[t-1]) +             # formula presented in the task
        irf_sum + 
        pandemic.df$sigma_error[t]
    }
  }
  
  # As all values have been safely placed, we can trim the data frame back down to its original size
  # and remove the columns which are no longer needed
  pandemic.df <- pandemic.df %>% 
    slice_head(n=T) %>% 
    select(country, year, ln_gdp, pandemic_01, war) -> pandemic.df

  return(pandemic.df)
}

# *** N countries ***

# We need to save the function in order for it to work in the next assignment where
# we use paralellization with the package `doParallel`
save(sim_one_country, file = "data/sim_one_country.Rdata")

# This function uses parralelization in order to combine multiple simulations gathered
# from the previous function `sim_one_country` 
simdat <- function(N, T, p_pand, p_war, sigma, coeff_lag_ln_gdp, impulse_response, sigma_initial_value, sigma_alpha){
  load("data/sim_one_country.Rdata")          # We need to load the function to our function environment
  
  cores <- parallel::detectCores()            # Here we detect the cores of the user of the script
  cluster <- makeCluster(min(cores, 8))       # In order to not "spread the butter too thin" we use 
  registerDoParallel(cluster)                 # a maximum of 8 cores
  
  sim_n <- foreach(i = 1:N,                   # the foreach-function is a special loop in the doParallel-package
                  .combine = rbind,
                  .packages = c("tidyverse", "magrittr")) %dopar%
    {
      sim_one_country(country = i,
                      T = T, 
                      p_pand = p_pand, 
                      p_war = p_war, 
                      sigma = sigma, 
                      coeff_lag_ln_gdp = coeff_lag_ln_gdp, 
                      impulse_response = impulse_response, 
                      sigma_initial_value = sigma_initial_value, 
                      sigma_alpha = sigma_alpha)
    }
  # Stop parallel backend
  stopCluster(cluster)
  return(sim_n)
}

```

With these two functions defined, we can apply them to the tests provided by the task, and see if they fulfill all the necessary requirements for further use.

```{r, eval=T, error=TRUE, message=FALSE}
# Tests for assignment 2. Leave this code chunk *unchanged* and 
# ensure you run the tests *after* the chunk with you answer to 
# assignment 2. 

assert_that(
  sim_one_country(
    country = 1,
    T = 5,
    p_pand = 1,
    p_war = 0,
    sigma = 0,
    coeff_lag_ln_gdp = 0,
    impulse_response = c(1),
    sigma_initial_value = 0,
    sigma_alpha = 0
  ) %>%
    filter(year > 1) %>%
    filter(ln_gdp == 1) %>%
    nrow() == 4,
  msg = "Impulse responses are not correct"
)


assert_that(
  all(
    sim_one_country(
      country = 1,
      T = 5,
      p_pand = 1,
      p_war = 0,
      sigma = 0,
      coeff_lag_ln_gdp = 0,
      impulse_response = c(1, 2, 3, 4),
      sigma_initial_value = 0,
      sigma_alpha = 0
    )$ln_gdp == c(0, 3, 6, 10, 10)
  ),
  msg = "Impulse response is not implemented correctly"
)

assert_that(
  all(
    sim_one_country(
      country = 1,
      T = 5,
      p_pand = 1,
      p_war = 0,
      sigma = 0,
      coeff_lag_ln_gdp = 0,
      impulse_response = rep(1, 10),
      sigma_initial_value = 0,
      sigma_alpha = 0
    )$ln_gdp == c(0, 2, 3, 4, 5)
  ),
  msg = "Function fails if impulse response is longer than 1:T"
)

assert_that(abs(sd(
  replicate(
    1000,
    sim_one_country(
      country = 1,
      T = 1,
      p_pand = 1,
      p_war = 0,
      sigma = 0,
      coeff_lag_ln_gdp = 0,
      impulse_response = c(0),
      sigma_initial_value = 1,
      sigma_alpha = 0
    )$ln_gdp
  )
) - 1) < .1,
msg = "Random number generation does not work"
)


assert_that(abs(mean(
  simdat(
    N = 1,
    T = 10000,
    p_pand = .1,
    p_war = 0,
    sigma = 0,
    coeff_lag_ln_gdp = 0,
    impulse_response = rep(1, 10),
    sigma_initial_value = 0,
    sigma_alpha = 0
  )$pandemic_01
) - .1) < .01,
msg = "Pandemic variable simulation does not work"
)


assert_that(
  simdat(
    N = 10,
    T = 5,
    p_pand = .1,
    p_war = 0,
    sigma = 1,
    coeff_lag_ln_gdp = 0,
    impulse_response = rep(1, 10),
    sigma_initial_value = 0,
    sigma_alpha = 0
  ) %>% nrow() == 50,
  msg = "The simdat function return wrong number of rows"
)

assert_that(
  length(unique(simdat(
    N = 100,
    T = 5,
    p_pand = .1,
    p_war = 0,
    sigma = 1,
    coeff_lag_ln_gdp = 0,
    impulse_response = rep(1, 10),
    sigma_initial_value = 0,
    sigma_alpha = 0
  )$country)) == 100,
  msg = "The simdat function return wrong number of countries"
)

```

## Problem 3

In this task we will make use of the IRF-estimator presented in the first assignment, and compare it to the actual values for IRF fed into the simulated data set. As we know the "real" IRF we can compare it to the estimation in order to evaluate the validity of the estimation. In order to reduce code repetition I have decided to make a set of functions which solves the tasks at hand.

```{r, eval=T, error=TRUE, message=TRUE}
# A function which calls the simdat-function with a specified coeff_lag_ln_gdp value.
simdat_coeff <- function(coeff_lag_ln_gdp){
  df <- simdat(
    N = 50,
    T = 1000,
    p_pand = .1,
    p_war = 0,
    sigma = 10,
    coeff_lag_ln_gdp = coeff_lag_ln_gdp,
    impulse_response = c(1, -1, 2, -2, 0, 0, 1),
    sigma_initial_value = 1,
    sigma_alpha = 5)
  return(df)
}

plot_simdat <- function(coeff_lag_ln_gdp, h){
  # Creating a tibble for IRF coefficient
  tibble(
    impulse = c(1, -1, 2, -2, 0, 0, 1),
    h = c(0:(length(impulse)-1))
  ) -> impulse.df 
  
  # Calling the simdat_coeff function
  simdat.df <- simdat_coeff(coeff_lag_ln_gdp)
  
  # Mapping the simulation data
  lapply(0:h, FUN = runreg, df = simdat.df) %>%
    bind_rows() %>%
    filter(rowname == "pandemic_01") %>%
    ggplot(aes(x = h)) +
    geom_line(aes(y = Estimate, color = "Beta Coeff Estimate"), size = 1, alpha = .8) +
    geom_ribbon(aes(
      ymin = (Estimate - 1.96 * `Std. Error`),
      ymax = (Estimate + 1.96 * `Std. Error`)
    ), alpha = .1) +
    geom_hline(yintercept = 0) +
    
    # Adding the real impulse response-function
    geom_line(aes(x = h, y = impulse, color = "IRF Coeff"), 
              data = impulse.df, size = .75) +
    
    # Adding labs
    labs(
      x = "Forecast cast horizon (h)",
      y = "Impulse response, percent",
      title = "Estimated impulse response of pandemics on GDP pr capita",
      subtitle = paste0("Coefficient of ln_gdp: ", coeff_lag_ln_gdp),
      color = "Linetype"
    ) +
    scale_color_manual(values = c("#000000", "#ed4a4a")) +
    theme_classic()
}

```

With these function defined we can call the `plot_simdat`-function and it will create a plot of the impulse response in percent over the `h` time period.

In this plot `coeff_lag_ln_gdp = 0`:

```{r, fig.width = 11}
plot_simdat(0, 40)
```

And in this plot `coeff_lag_ln_gdp = 0.96`:

```{r, fig.width = 11}
plot_simdat(.96, 40)
```

# Discussion

S2020 points out that the fixed effects estimator is knows to be biased in a dynamic panel setting, which in turn means that the model is subject to systematic error when used to analyze data that change over time. However, this effect decreases over time, and because of the large time frame of 765 years, this effect can be safely ignored.  

The figures which have been presented above may point out some flaws in this though process however. The dataset which is used by S2020 many missing values over the course of the given time frame. The simulated data set which we have created, do not have any missing values. This might cause the time-frame that S2020 is talking about to be much smaller in reality than 765 years. Furthermore, if a coefficient is biased it is systematically to large or too small based some type of error, typically sampling errors, measurement errors, omitted variable bias, or omitted group bias. This may in turn affect other coefficients as well as there are systematic errors in the creation of the regression.

## Problem 4
For the rest of the case I will base my results and assumptions on the provided dataset `df`.  

Based on the newly defined function for estimating the lead of `ln_gdp` we can create a function which has `K` as an input variable in the function which runs the regression. This allows us to choose the amount of lags put into the regression.

```{r, eval=T, error=TRUE, message=TRUE}
runreg_baseline <- function(h, df, K){
  df -> df.dt                                                                               # Note that:
  setDT(df.dt)[, paste0("pandemic_01_lag_", 0:K) := data.table::shift(pandemic_01, 0:K)][]  # j = 0
  setDT(df.dt)[, paste0("ln_gdp_lag_", 1:K) := data.table::shift(ln_gdp, 1:K)][]            # m = 1
  setDF(df.dt) %>%
    mutate(country = factor(country)) %>%
    group_by(country) %>%
    mutate(
      
      # Lead ln_gdp
      lead_ln_gdp = lead(ln_gdp, h, order_by = year),
    
      # War
      lag_1_war = lag(war, 1, order_by = year),
      vienna = case_when(year >= 1815 ~ 1, TRUE ~ 0),
      ww2 = case_when(year >= 1945 ~ 1, TRUE ~ 0),
      oil = case_when(year >= 1973 ~ 1, TRUE ~ 0),
      vienna_t = vienna * year,
      ww2_t = ww2 * year,
      oil_t = oil * year
    ) %>% select(-ln_gdp) -> df.lag           # The ln_gdp should not be a part of the model (m=1) and
                                              # the lead of ln_gdp is the response variable
  # Regression model
  lm(lead_ln_gdp ~ ., data = df.lag) %>%    
      summary() %>%
      .$coefficients %>%
      as.data.frame() %>%
      rownames_to_column() %>%
      as_tibble() %>%
      mutate(h = h) -> coeff.df

  return(coeff.df)
}

# Because of limitations of the pmap function, I deem it simpler to create a
# simpler version of the runreg_baseline function which only needs the h-variable,
# as K=30 and df=df is constant and do not need to be iterated over in the same way
runreg_baseline_simp <- function(h) {runreg_baseline(h = h,
                                                     df = df,
                                                     K = 30)}

map_dfr(0:40, runreg_baseline_simp) %>%                  # The map_dfr function is useful
  filter(substr(rowname, 1, 11) == "pandemic_01") %>%    # when combining dataframes
  group_by(h) %>%
  summarise(sum_estimate = sum(Estimate),
            mean_std = mean(`Std. Error`)) %>%     # We use the sum as the regression is based
  ggplot(aes(x = h)) +                             # on the sum of these effects
  geom_line(aes(y = sum_estimate)) +
  geom_ribbon(aes(
    ymin = (sum_estimate - 1.96 * mean_std),       # Unsure about what to do about the st.error,
    ymax = (sum_estimate + 1.96 * mean_std)        # but the mean error could prove somewhat useful
  ), alpha = .1) +                                 # as we are dealing with sums of lags (sum(std) would
  geom_hline(yintercept = 0) +                     # not be useful as it is really large)
  xlab("Fcast horizon (h)") +
  ylab("Sum of Impulse response, percent") +
  ggtitle(paste0("Estimated total impulse response of pandemics on GDP pr capita with K = 30")) +
  theme_classic()

```
  
Although there is some uncertainty in regards to the statistical methodology of taking the sum of the lagged coefficients and the mean of the standard error, I did not find another solution which captured the resulting coefficients without losing more information (i.e. aggregating them).

```{r, eval=T, error=TRUE, message=FALSE}

# Tests for assignment 4. Leave this code chunk *unchanged* and 
# ensure you run the tests *after* the chunk with you answer to 
# assignment 4. 


assert_that(
  runreg_baseline(0, df, 40) %>%
    filter(substr(rowname, 1, 11) == "pandemic_01") %>%
    nrow(.) == 41,
  msg = "Function does not have the right number of lags for pandemics"
)

assert_that(
  runreg_baseline(0, df, 70) %>%
    filter(substr(rowname, 1, 6) == "ln_gdp") %>%
    nrow(.) == 70,
  msg = "Function does not have the right number of lags for ln_gdp"
)
```

## Problem 5

In this task there are is lot of *artistic freedom* in creating a map which illustrates pandemics over time. I have therefore chosen to create an animated map which represents various levels of pandemics in the world across the time-span of the set of data, which is `765 years`. I will explain some of my choices within the comments of the code provided below, and I will go through some weaknesses of the map at the end.  

In order to get a better sense of how to plot the data I will first of all take a quick summary of the pandemic data in order to be better situated to plot it. As I will focus on the pandemics themselves I have opted to in this part remove all values containing 0, as I would like to know the approximate severety of these pandemics.

```{r}
pandemic.data <-
  read_excel("Stefanski-pandemic-data.xlsx")

pandemic.data$pandemic_pc[pandemic.data$pandemic_pc > 0] %>% 
  summary()
```
  
From this summary one can see that 75% of all pandemics in the set of data kill below 1% of the population, and the median pandemic kills around 0.32% of the population. In order for the large pandemics such as the one that kills 50% of the population not to overshadow the much more common smaller pandemics I will create a set of pandemic groups that show the severity of the pandemic. This scale will not be linear because of the disproportionate distribution of the death tolls, especially since the mean is very high compared to the median which points to a few outliers.    

I have used a function framework to create the animated plots, where the `interval` is defined as the number of years between each frame. The data from this period will be aggregated based on the largest pandemic within any given time-frame. Long lasting pandemics might therefore not be accurately represented (as long as interval is chosen to be higher than 1).

```{r, eval=T, error=TRUE, message=TRUE}
plot.pandemic <- function(interval){
  
  # Function for defining a "floor value" for a given year
  floor_date_y = function(year){return(year - (year %% interval))}                  # Grouping years per interval

  
  # Then we load in the original data set in order to
  # be able to use all variables when creating a map
  pandemic.data <-
    read_excel("Stefanski-pandemic-data.xlsx") %>% 
    mutate(country = ifelse(country == "SUN", "RUS", country),
           year_interval = floor_date_y(year),
           pandemic_pc = as.numeric(pandemic_pc)) %>% 
    
    group_by(country, year_interval) %>%                                            # Group into country and interval
    summarise(max_pop_loss = max(pandemic_pc)) %>% 
  
  # Because of the time frame, it might be inaccurate to plot the exact figures of the
  # death tolls. Therefore I have used the information from the summary above to create some
  # categories of pandemics which I will use to make the plot later
    mutate(section = ifelse(max_pop_loss == 0, "0%",                                # I use the max death toll to plot
                             ifelse(max_pop_loss < .08, "<0.08%",                   # the most severe pandemic in a
                                    ifelse(max_pop_loss < .32, "<0.32%",            # specific time interval
                                           ifelse(max_pop_loss < 1, "<1%",
                                                  ifelse(max_pop_loss < 3, "<3%",
                                                         ifelse(max_pop_loss < 10, "<10%",
                                                                ifelse(max_pop_loss < 30, "<30%", ">30%"))))))),
           # This is a formatting option to make sure the order in the legend in the plot is correct
           group = factor(section,
                          levels = c("0%", "<0.08%", "<0.32%", "<1%", "<3%", "<10%", "<30%", ">30%")))
  
  # We filter out all the countries included in the dataframe
  # !Note! SUN is used in the pandemic.data (Soviet Union) but in our
  # world sf-dataset they are defined as Russia. Even though they
  # are not the same historically we will treat them as the same entity
  world <- ne_countries(scale = "medium", returnclass = "sf")
  
  # Then we extract the data to plot the countries in our pandemic dataset
  pandemic.sf <- world %>%
    filter(iso_a3 %in% unique(pandemic.data$country) | iso_a3 == "RUS") %>% 
    select(iso_a3) %>% 
    left_join(pandemic.data, by = c("iso_a3" = "country"))
  
  # We create a custom color scale to plot the "severity" of the various pandemics
  color_scale <- c("#c4c4c4","#f5dfdf","#f5aeae","#e07575", "#e04c4c", "#cf4c40", "#e30505", "#a60202")
  
  # Creating a gif with a set year interval with the gganimate package
  animation <- ggplot() + 
    geom_sf(aes(geometry =geometry), fill = "black", color = "white", alpha = 0.1, data = world)+
    geom_sf(aes(geometry = geometry, fill = group), data = pandemic.sf) +
    theme_void() +
    labs(
      title = paste0(interval, ' year period: {current_frame}'),
      fill = "% Dead from pandemics"
    ) +
    scale_fill_manual(values = color_scale) +
    transition_manual(year_interval)

  animate(animation, height = 3.5, width = 9, units ="in", res = 300,
          duration = 60,
          fps = 5) 
}

# Then we can call the function with a given time interval. I will use 10 years in this example
plot.pandemic(10)

```

This map shows us some very interesting results, which somewhat agree with history. It starts around the time of the bubonic plague caused by traders on the silk road, and when things are calm in Europe various pandemics ravage the new world, which was caused by transatlantic travel in the Age of Exploration. When human civilization became "global" in the 18th century pandemics were rampant and spread quickly and easily by boat and other means of travel. When modern medicine and sanitation emerged one can see that the rate of death became nearly instantly zero. The map can therefore be assumed to be accurate at least when looking at it with a broad historic perspective. For this map it is also important to note that modern borders are by no means representative of the political entities of the time of recording the data, which might also distort the results.  

The countries in which we has no data for are greyed out but still visible on the map. The speed of the showcase `.gif` might change based on the chosen interval. The function has been designed with intervals between 10 and 50 in mind.

#### Session info

Leave this part unchanged. The cell below prints which packages and versions were used for creating the html-file.

```{r, eval=T}
sessionInfo()
```
